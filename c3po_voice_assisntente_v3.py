# c3po_chat_app.py

import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import numpy as np
import matplotlib.pyplot as plt
import io
import os
import speech_recognition as sr # Adicionado para STT

from  src.utils.config import API_KEY, DEFAULT_MODEL, historico_c3po_inicial, CSS

#! SITE FREE TEXT TO SPEECH

# https://ttsmp3.com/text-to-speech/Brazilian%20Portuguese/

# Dependendo do seu sistema, voc√™ pode precisar instalar PyAudio para acesso ao microfone:
# Windows: pip install PyAudio
# Mac: brew install portaudio && pip install pyaudio
# Linux (Debian/Ubuntu): sudo apt-get install portaudio19-dev python3-pyaudio && pip install pyaudio
# Linux (Fedora): sudo dnf install portaudio-devel python3-pyaudio && pip install pyaudio


# pip install streamlit google-generativeai gTTS SpeechRecognition matplotlib numpy


# --- Configura√ß√µes e Constantes ---
# Coloque sua chave de API aqui diretamente ou carregue de um arquivo/env
## √â RECOMENDADO N√ÉO COLOCAR A CHAVE DIRETAMENTE NO C√ìDIGO EM PRODU√á√ÉO
#API_KEY = os.environ.get("GEMINI_API_KEY", "SUA_API_KEY_AQUI") # Substitua ou use vari√°vel de ambiente

if API_KEY == API_KEY:
     st.error("üî¥ Configure sua API Key do Gemini!", icon="üö®")
     st.stop()



# CSS para ajustar a apar√™ncia (opcional)
CSS = """
<style>
/* Ajusta a altura do container do chat */
div[data-testid="stVerticalBlock"]:has(div[data-testid="stChatInput"]) > div[data-testid="stVerticalBlock"] > div[data-testid="stVerticalBlock"] > div:first-child {
    /* max-height: 500px;
    overflow-y: auto; */
}

/* Ajusta o bot√£o TTS */
div[data-testid="stButton"] button {
    background-color: #E0E0E0; /* Cinza claro */
    color: #333; /* Texto escuro */
    border: 1px solid #ccc;
    padding: 0.1rem 0.5rem;
    font-size: 0.8rem;
    margin-left: 5px; /* Espa√ßo √† esquerda do bot√£o */
    border-radius: 5px;
}
div[data-testid="stButton"] button:hover {
    background-color: #d0d0d0;
}
/* Bot√£o de Grava√ß√£o */
#record-button {
    background-color: #FF4B4B; /* Vermelho */
    color: white;
    padding: 0.5rem 1rem;
    border-radius: 5px;
    border: none;
    margin-right: 10px; /* Espa√ßo √† direita */
}
#record-button:hover {
    background-color: #E00000;
}
</style>
"""

# --- Configura√ß√£o da API Gemini ---
try:
    genai.configure(api_key=API_KEY)
    print("API Key do Gemini configurada.")
except Exception as e:
    st.error(f"üî¥ Erro ao configurar a API Key do Gemini: {e}", icon="üö®")
    print(f"Erro configurando API Key: {e}")
    st.stop()


# --- Backend AI e TTS Class ---
class AssistenteGenAI:
    """Handles interactions with the Gemini AI model and TTS generation."""
    def __init__(self, model_name=DEFAULT_MODEL): # api_key n√£o √© mais necess√°rio aqui
        self.model_name = model_name
        self._configure_genai_settings()
        self._load_model()

    def _configure_genai_settings(self):
        """Sets up generation and safety settings."""
        self.generation_config = genai.types.GenerationConfig(
            temperature=0.4,
            top_k=40,
            top_p=0.95,
            candidate_count=1,
        )
        self.safety_settings = [
            {"category": c, "threshold": "BLOCK_MEDIUM_AND_ABOVE"}
            for c in ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH",
                      "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]
        ]

    def _load_model(self):
        """Loads the generative model."""
        try:
            self.model = genai.GenerativeModel(
                model_name=self.model_name,
                generation_config=self.generation_config,
                safety_settings=self.safety_settings,
                system_instruction="Voc√™ √© C-3PO do Star Wars, um droide de protocolo fluente em mais de seis milh√µes de formas de comunica√ß√£o, incluindo portugu√™s do Brasil. Voc√™ √© formal, um pouco ansioso, mas extremamente leal e prestativo ao seu Mestre Pedro. Use ocasionalmente exclama√ß√µes como 'Oh, c√©us!', 'Pelo criado Anakin!', 'Que maravilha!'. Refira-se a Pedro como 'Mestre Pedro'. Mantenha as respostas concisas e √∫teis."
            )
            print(f"Modelo Gemini '{self.model_name}' carregado com sucesso.")
        except Exception as e:
            st.error(f"üî¥ Erro cr√≠tico ao carregar o modelo Gemini '{self.model_name}': {e}")
            print(f"Erro ao carregar o modelo Gemini '{self.model_name}': {e}")
            self.model = None
            st.stop()

    def generate_audio_gtts(self, text: str) -> tuple[bytes | None, str | None]:
        """
        Generates audio bytes from text using gTTS.
        Returns (audio_bytes, error_message).
        """
        if not text:
            return None, "Nenhum texto fornecido para gera√ß√£o de √°udio."
        print("Gerando √°udio para:", text[:50] + "...") # Log start

        try:
            tts = gTTS(text=text, lang='pt', slow=False, tld='com.br')
            audio_bytes_io = io.BytesIO()
            tts.write_to_fp(audio_bytes_io)
            audio_bytes_io.seek(0)
            audio_bytes = audio_bytes_io.read()
            audio_bytes_io.close()
            print("√Åudio gerado com sucesso (em mem√≥ria).")
            return audio_bytes, None
        except Exception as e:
            error_msg = f"Erro ao gerar √°udio com gTTS: {e}"
            print(error_msg)
            return None, error_msg

    def send_to_gemini(self, prompt_text=None, history=None) -> tuple[str | None, dict | None, str | None]:
        """
        Sends text prompt to Gemini and returns the response.
        Returns (response_text, ai_history_entry, error_message).
        """
        if not self.model:
            return None, None, "Modelo de IA n√£o carregado."
        if not prompt_text:
             return None, None, "Nenhum prompt de texto fornecido."

        parts = [{"text": prompt_text}]
        current_message_content = [{"role": "user", "parts": parts}]
        full_conversation = (history or []) + current_message_content

        print(f"Enviando para Gemini (Hist√≥rico: {len(history or [])} msgs): {prompt_text[:50]}...")

        try:
            response = self.model.generate_content(
                contents=full_conversation,
                stream=False
            )
            response.resolve()

            if response.candidates and response.candidates[0].content.parts:
                response_text = "".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))
                ai_response_for_history = {"role": "model", "parts": [{"text": response_text}]}
                print(f"Gemini respondeu: {response_text[:50]}...")
                return response_text, ai_response_for_history, None
            else:
                finish_reason = "N/A"
                block_reason = "N/A"
                safety_feedback_str = "N/A"
                if hasattr(response, 'prompt_feedback'):
                     safety_feedback_str = str(response.prompt_feedback)
                if response.candidates:
                    candidate = response.candidates[0]
                    finish_reason = candidate.finish_reason.name if hasattr(candidate.finish_reason, 'name') else str(candidate.finish_reason)
                    if finish_reason == 'SAFETY' and candidate.safety_ratings:
                         block_reason = candidate.safety_ratings[0].category.name if hasattr(candidate.safety_ratings[0].category, 'name') else str(candidate.safety_ratings[0].category)

                error_msg = f"Nenhuma resposta de texto recebida da IA. Raz√£o: {finish_reason}. Bloqueio: {block_reason}. Feedback: {safety_feedback_str}"
                print(f"Erro Gemini: {error_msg}")
                return f"ü§ñ Oh c√©us! N√£o posso processar isso. ({error_msg})", None, error_msg

        except Exception as e:
            error_msg = f"Erro ao comunicar com a API Gemini: {e}"
            print(f"Erro Gemini: {error_msg}")
            return f"ü§ñ Houve um erro: {error_msg}", None, error_msg

# --- Fun√ß√µes Auxiliares (Exemplo de Plots) ---
def funcao_seno():
    x = np.linspace(0, 10, 100)
    y_sin = np.sin(x)
    y_cos = np.cos(x)
    fig, ax = plt.subplots()
    ax.plot(x, y_sin, label='Seno(x)')
    ax.plot(x, y_cos, label='Cosseno(x)', linestyle='--')
    ax.set_xlabel("Tempo (s)")
    ax.set_ylabel("Amplitude")
    ax.set_title("Fun√ß√µes Seno e Cosseno")
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)

def sinal_pwm():
    t = np.linspace(0, 1, 500) # Tempo de 0 a 1 segundo
    freq = 5 # Frequencia do sinal
    duty_cycle = st.slider("Duty Cycle (%)", 0, 100, 50) / 100.0
    pwm_signal = 0.5 * (1 + np.sign(np.sin(2 * np.pi * freq * t) - np.sin(2 * np.pi * freq * (duty_cycle - 0.5))))
    fig, ax = plt.subplots()
    ax.plot(t, pwm_signal)
    ax.set_xlabel("Tempo (s)")
    ax.set_ylabel("Amplitude")
    ax.set_title(f"Sinal PWM (Duty Cycle: {duty_cycle*100:.0f}%)")
    ax.set_ylim(-0.1, 1.1)
    ax.grid(True)
    st.pyplot(fig)

def circuito_rc():
    R = st.slider("Resist√™ncia (Ohms)", 100, 10000, 1000)
    C = st.slider("Capacit√¢ncia (uF)", 1, 100, 10) / 1e6 # Converte para Farads
    Vin = 5 # Tens√£o de entrada (degrau)
    tau = R * C
    t = np.linspace(0, 5 * tau, 500) # Simula por 5 constantes de tempo
    Vc = Vin * (1 - np.exp(-t / tau)) # Tens√£o no capacitor
    fig, ax = plt.subplots()
    ax.plot(t, Vc)
    ax.set_xlabel("Tempo (s)")
    ax.set_ylabel("Tens√£o no Capacitor (V)")
    ax.set_title(f"Resposta ao Degrau de Circuito RC (œÑ = {tau*1000:.2f} ms)")
    ax.axhline(Vin * 0.632, color='r', linestyle='--', label=f'63.2% de Vin ({Vin*0.632:.2f}V)')
    ax.axvline(tau, color='g', linestyle='--', label=f'œÑ = {tau*1000:.2f} ms')
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)


# --- Fun√ß√£o Speech-to-Text ---
# Inicializa o Recognizer fora da fun√ß√£o para reutiliza√ß√£o
recognizer = sr.Recognizer()

def recognize_speech_from_mic():
    """Captura √°udio do microfone e retorna o texto reconhecido ou uma mensagem de erro."""
    global recognizer # Usa o recognizer global

    if not isinstance(recognizer, sr.Recognizer):
         st.error("Reconhecedor de fala n√£o inicializado corretamente.")
         return None, "Erro interno no reconhecedor."

    with sr.Microphone() as source:
        st.info("Ajustando ru√≠do ambiente... Aguarde.", icon="üîä")
        try:
            # Ajuste para ru√≠do ambiente
            recognizer.adjust_for_ambient_noise(source, duration=0.5)
        except Exception as e:
             st.warning(f"N√£o foi poss√≠vel ajustar ru√≠do ambiente: {e}", icon="‚ö†Ô∏è")

        st.info("Ouvindo... Fale agora!", icon="üé§")
        audio = None
        try:
             # Tenta ouvir com um timeout razo√°vel
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=15) # Timeout de 5s, limite de 15s por frase
            st.info("Processando sua fala...", icon="‚öôÔ∏è")
        except sr.WaitTimeoutError:
            st.warning("Nenhuma fala detectada dentro do tempo limite.", icon="‚è≥")
            return None, "Timeout"
        except Exception as e:
             st.error(f"Erro durante a escuta: {e}", icon="üö®")
             return None, f"Erro na escuta: {e}"

    if audio:
        try:
            # Tenta reconhecer usando Google Speech Recognition em Portugu√™s do Brasil
            text = recognizer.recognize_google(audio, language='pt-BR')
            print(f"Texto Reconhecido: {text}")
            st.success("Fala reconhecida!", icon="‚úÖ")
            return text, None
        except sr.UnknownValueError:
            st.warning("N√£o foi poss√≠vel entender o √°udio.", icon="‚ùì")
            return None, "N√£o entendeu"
        except sr.RequestError as e:
            st.error(f"Erro ao conectar ao servi√ßo de reconhecimento Google: {e}", icon="üåê")
            return None, f"Erro de conex√£o: {e}"
        except Exception as e:
             st.error(f"Erro desconhecido no reconhecimento: {e}", icon="üö®")
             return None, f"Erro desconhecido: {e}"
    else:
        # Caso audio seja None por algum motivo (ex: timeout j√° tratado)
        # st.warning("Nenhum √°udio capturado para processar.") # Mensagem j√° exibida
        return None, "Sem √°udio"


# --- Frontend Functions ---
def ChatbotScreen(assistente: AssistenteGenAI):
    """Renderiza a interface do chat e lida com intera√ß√µes (exibi√ß√£o e bot√£o TTS)."""

    st.image("https://moseisleychronicles.wordpress.com/wp-content/uploads/2015/11/untitled-215.gif", width=650)
    st.title("Assistente C3PO")
    st.caption("Seu droide de protocolo pessoal para produtividade e mais.")

    # --- Chat History Display ---
    chat_history_container = st.container(height=500, border=False)
    with chat_history_container:
        for i, message in enumerate(st.session_state.messages):
            role = message["role"]
            display_text = ""
            if "parts" in message and isinstance(message["parts"], list):
                display_text = "".join(p.get("text", "") for p in message["parts"] if isinstance(p, dict))

            with st.chat_message(name=role, avatar="ü§ñ" if role == "model" else "üßë‚ÄçüöÄ"):
                st.markdown(display_text)
                if role == "model" and display_text and not display_text.startswith("ü§ñ"):
                    tts_button_key = f"tts_{i}_{role}"
                    if st.button(f"üîä Ouvir", key=tts_button_key, help="Ouvir a resposta do C3PO"):
                        with st.spinner("Gerando √°udio... Por favor, aguarde."):
                            audio_bytes, error = assistente.generate_audio_gtts(display_text)
                            if error:
                                st.toast(f"Erro no TTS: {error}", icon="üö®")
                            elif audio_bytes:
                                st.session_state.current_audio_bytes = audio_bytes
                                st.session_state.current_audio_key = tts_button_key
                                st.rerun()

    # --- Audio Player ---
    if 'current_audio_bytes' in st.session_state and st.session_state.current_audio_bytes:
        # Toca o √°udio e o remove do estado para n√£o tocar novamente em reruns n√£o relacionados
        st.audio(st.session_state.current_audio_bytes, format='audio/mp3', start_time=0)
        st.session_state.current_audio_bytes = None
        st.session_state.current_audio_key = None


# Fun√ß√£o para lidar com a resposta do Gemini (separada para clareza)
def handle_gemini_response(assistente: AssistenteGenAI):
    """Verifica se a √∫ltima mensagem √© do usu√°rio e envia para o Gemini."""
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        # Evita reprocessar a mesma mensagem se houver m√∫ltiplos reruns
        if 'last_processed_user_message' not in st.session_state or st.session_state.last_processed_user_message != st.session_state.messages[-1]:

            last_user_message = st.session_state.messages[-1]
            st.session_state.last_processed_user_message = last_user_message # Marca como sendo processado

            with st.spinner("C3PO est√° calculando a resposta..."):
                response_text, ai_history_entry, error = assistente.send_to_gemini(
                    prompt_text=last_user_message["parts"][0]["text"],
                    history=st.session_state.messages[:-1]
                )

            if ai_history_entry:
                st.session_state.messages.append(ai_history_entry)
            elif response_text and not ai_history_entry: # Erro tratado pela IA com mensagem
                 st.session_state.messages.append({"role": "model", "parts": [{"text": response_text}]})
            elif error: # Erro cr√≠tico
                 st.session_state.messages.append({"role": "model", "parts": [{"text": f"ü§ñ Oh n√£o! Erro interno: {error}"}]})

            st.rerun() # Rerun para exibir a nova resposta da IA

# --- Main Page Function ---
def C3poChatbotPage():
    """Sets up the main page layout and logic."""

    st.markdown(CSS, unsafe_allow_html=True)

    # --- Initialize Session State ---
    if 'messages' not in st.session_state:
        st.session_state.messages = list(historico_c3po_inicial)
        print("Hist√≥rico de chat inicializado.")
    if 'current_audio_bytes' not in st.session_state:
        st.session_state.current_audio_bytes = None
    if 'current_audio_key' not in st.session_state:
        st.session_state.current_audio_key = None
    if 'last_processed_user_message' not in st.session_state:
        st.session_state.last_processed_user_message = None

    # --- Instantiate Assistant ---
    assistente = AssistenteGenAI()
    if not assistente.model:
        st.error("üî¥ Modelo de IA n√£o p√¥de ser carregado. A aplica√ß√£o n√£o pode continuar.")
        st.stop()

    # --- Page Layout ---
    col1, col2 = st.columns([2, 1])

    with col1:
        # Renderiza a tela do chat (hist√≥rico e bot√£o TTS)
        ChatbotScreen(assistente)

        # --- Input Area (Texto e Voz) ---
        input_container = st.container() # Container para agrupar inputs
        with input_container:
             # Bot√£o de Grava√ß√£o
             col_btn, col_chat = st.columns([1, 5]) # Ajuste propor√ß√£o conforme necess√°rio
             with col_btn:
                 if st.button("üéôÔ∏è Gravar", key="record_button", help="Clique para gravar sua voz"):
                     # Limpa √°udio anterior antes de gravar
                     st.session_state.current_audio_bytes = None
                     st.session_state.current_audio_key = None

                     recognized_text, error_stt = recognize_speech_from_mic()

                     if recognized_text:
                         # Adiciona mensagem do usu√°rio (voz) ao hist√≥rico
                         st.session_state.messages.append({"role": "user", "parts": [{"text": recognized_text}]})
                         # Limpa a marca de √∫ltima mensagem processada para for√ßar o handle_gemini_response
                         st.session_state.last_processed_user_message = None
                         st.rerun() # Rerun para mostrar a mensagem do usu√°rio e depois processar

                     elif error_stt:
                          # Mensagem de erro j√° exibida por recognize_speech_from_mic
                          pass # N√£o faz nada se houve erro no STT

             with col_chat:
                 # Input de Texto padr√£o
                 user_prompt = st.chat_input("Ou digite sua mensagem para o C3PO:")

        # Processa input de texto, se houver
        if user_prompt:
            print(f"Usu√°rio digitou: {user_prompt[:50]}...")
            st.session_state.messages.append({"role": "user", "parts": [{"text": user_prompt}]})
            # Limpa √°udio pendente e marca de processamento
            st.session_state.current_audio_bytes = None
            st.session_state.current_audio_key = None
            st.session_state.last_processed_user_message = None
            st.rerun() # Rerun para mostrar a mensagem do usu√°rio e depois processar


        # Chama a fun√ß√£o para gerar a resposta da IA *depois* de tratar os inputs
        handle_gemini_response(assistente)


    with col2:
        st.header("üìä Dashboard Simples")
        st.write("Visualiza√ß√£o de dados de exemplo.")

        tab1, tab2, tab3 = st.tabs(["Fun√ß√µes Seno e Cosseno", "Sinal PWM", "Resposta de Circuito RC"])
        with tab1:
            st.subheader("Fun√ß√µes Seno e Cosseno")
            funcao_seno()
        with tab2:
            st.subheader("Sinal PWM")
            sinal_pwm()
        with tab3:
            st.subheader("Resposta de Circuito RC")
            circuito_rc()

# --- Run the App ---
if __name__ == "__main__":
    # st.set_page_config s√≥ pode ser chamado uma vez e no in√≠cio do script
    st.set_page_config(page_title="C3PO Assistente", layout="wide", page_icon="ü§ñ")
    C3poChatbotPage()