# ------------------- Import Libraries -------------------
import vosk
import pyaudio
import json
import pygame
import google.generativeai as genai
from openai import OpenAI
import io
from cvzone.SerialModule import SerialObject
from time import sleep

# ------------------- Initializations -------------------

# ------------------- Servo Movements

# Create a Serial object with three digits precision for sending servo angles
arduino = SerialObject(digits=3)

# Initialize the last known positions for the three servos: Left (LServo), Right (RServo), Head (HServo)
# LServo starts at 180 degrees, RServo at 0 degrees, and HServo at 90 degrees
last_positions = [180, 0, 90]

# ------------------- AI speech integration portion
# Initialize Pygame mixer
pygame.mixer.init()

# Initialize VOSK model
model = vosk.Model("../Resources/vosk-model-en-us-0.22")
recognizer = vosk.KaldiRecognizer(model, 16000)

# Configure Gemini API with your API key
genai.configure(api_key="AIzaSyAmbzv22IoSmVszcl5g2TI1-gyMmODPG9o")

# Configure OpenAI Text-to-Speech API
client = OpenAI(api_key="sk-proj-GyXnA7wkEF0Euzt7WKhTT3BlbkFJsWytiP1LcfhC80pLtnAU")


# ------------------- Utility Functions -------------------

def play_sound(file_path):
    """
    Plays an audio file using pygame.

    Args:
        file_path (str): Path to the audio file.
    """
    pygame.mixer.music.load(file_path)
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():  # Wait for audio to finish playing
        pygame.time.Clock().tick(5)

# ------------------- Speech-to-Text Function -------------------

def listen_with_vosk():
    """
    Captures audio from the microphone and converts it to text using VOSK.

    Returns:
        str: Transcribed text from speech.
    """
    mic = pyaudio.PyAudio()  # Initialize microphone
    stream = mic.open(
        format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8192
    )
    stream.start_stream()
    print("Listening ...")
    play_sound("../Resources/listen.mp3")  # Play listening sound

    while True:
        data = stream.read(8192)
        if len(data) == 0:  # Skip if no audio data
            continue

        if recognizer.AcceptWaveform(data):  # Recognize speech
            play_sound("../Resources/convert.mp3")  # Play conversion sound
            result = recognizer.Result()  # Get result from recognizer
            text = json.loads(result)["text"]  # Extract text
            print("You said: " + text)
            return text

# ------------------- AI Text Generation Function -------------------

def gemini_api(text):
    """
    Sends input text to the Gemini API and retrieves the generated response.

    Args:
        text (str): Input text for the API.

    Returns:
        str: Generated response text from Gemini API.
    """
    # Initialize a genAI model
    model = genai.GenerativeModel(model_name="gemini-1.5-flash-latest")

    # Generate a response based on the input text
    response = model.generate_content(text)
    print(response.text)  # Print the response
    return response.text

# ------------------- Text-to-Speech Function -------------------

def openai_text_to_speech(text):
    """
    Converts input text to speech using OpenAI's Text-to-Speech API.

    Args:
        text (str): Text to convert to speech.

    Returns:
        bytes: Binary audio content generated by the API.
    """
    # Generate speech
    response = client.audio.speech.create(
        model="tts-1",
        voice="shimmer",
        input=text
    )
    # Extract audio content from the response
    audio_content = response.read()  # Read the binary content
    return audio_content

def play_audio(audio_bytes):
    """
    Plays audio content using pygame.

    Args:
        audio_bytes (bytes): Binary audio content to play.
    """
    pygame.mixer.init()
    pygame.mixer.music.load(io.BytesIO(audio_bytes))  # Load audio from bytes
    pygame.mixer.music.play()
    while pygame.mixer.music.get_busy():  # Wait for playback to finish
        pygame.time.Clock().tick(10)


# ------------------- Movement Functions -------------------

# Function to smoothly move servos to target positions
def move_servo(target_positions, delay=0.0001):
    """
    Moves the servos smoothly to the target positions.

    :param target_positions: List of target angles [LServo, RServo, HServo]
    :param delay: Time delay (in seconds) between each incremental step
    """
    global last_positions  # Use the global variable to track servo positions
    # Calculate the maximum number of steps required for the largest position difference
    max_steps = max(abs(target_positions[i] - last_positions[i]) for i in range(3))

    # Incrementally move each servo to its target position over multiple steps
    for step in range(max_steps):
        # Calculate the current position of each servo at this step
        current_positions = [
            last_positions[i] + (step + 1) * (target_positions[i] - last_positions[i]) // max_steps
            if abs(target_positions[i] - last_positions[i]) > step else last_positions[i]
            for i in range(3)
        ]
        # Send the calculated positions to the Arduino
        arduino.sendData(current_positions)
        # Introduce a small delay to ensure smooth motion
        sleep(delay)

    # Update the last known positions to the target positions
    last_positions = target_positions[:]


def hello_gesture():
    """
    Makes Emma wave hello by moving the right servo back and forth.
    """
    global last_positions
    # Move right arm to start waving
    move_servo([last_positions[0], 180, last_positions[2]])
    for _ in range(3):  # Perform the waving motion 3 times
        move_servo([last_positions[0], 150, last_positions[2]])  # Move arm slightly down
        move_servo([last_positions[0], 180, last_positions[2]])  # Move arm back up
    # Reset arm to original position
    move_servo([last_positions[0], 0, last_positions[2]])


# ------------------- Main Loop -------------------

while True:

    # Move Emma to casual gesture
    move_servo([180, 0, 90], delay=0.001)

    # Listen for speech input
    text = listen_with_vosk()

    # Waves if "hello Emma"
    if "hello" in text.lower() or "emma" in text.lower():
        print("Triggering Hello Gesture...")
        hello_gesture()

        response_text = "Hello! How can I assist you today?"
        audio_content = openai_text_to_speech(response_text)
        play_audio(audio_content)

    # Normal conversation
    else:
        print(f"Processing input: {text}")
        ai_response = gemini_api(text)
        audio_content = openai_text_to_speech(ai_response)
        play_audio(audio_content)

